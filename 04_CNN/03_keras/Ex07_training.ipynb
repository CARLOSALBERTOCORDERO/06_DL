{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Ex07_training.ipynb","provenance":[{"file_id":"1-SzGPs1Bo7BnPiwhMH66D2uy_9NYXvgD","timestamp":1570577817835}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"26KJjVGTRAzr","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator       # Para preprocesar imágenes\n","from tensorflow.python.keras import optimizers                                   # Utilizaremos el algoritmo Adam\n","from tensorflow.python.keras.models import Sequential                            # Modelos secuenciales, capas en orden\n","from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation   # Capas para la ConvNet\n","from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D           # Capas para la ConvNet\n","from tensorflow.python.keras import backend as k                                 # Permite gestionar sesiones en background"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ysy_tIx8cruk","colab_type":"code","outputId":"f628984c-92c8-48b1-beda-0c445e53d01d","executionInfo":{"status":"ok","timestamp":1570566677567,"user_tz":300,"elapsed":2056,"user":{"displayName":"ocapj","photoUrl":"","userId":"01319100646892058440"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Mount the Google Drive to Google Colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EtSuaNhNRAz1","colab_type":"code","colab":{}},"source":["k.clear_session();\n","\n","train_data = None\n","test_data = None\n","\n","# Número de iteraciones sobre todo el dataset de entrenamiento\n","epochs = None\n","\n","# Dimensiones de las imágenes para procesar\n","n_H, n_W = None, None\n","\n","# Utilizaremos mini-batch\n","batch_size = None\n","\n","# Número de iteraciones que vamos a procesar la información en cada epoca (entrenamiento)\n","steps = None\n","\n","# Número de iteraciones que vamos a procesar la información en cada epoca (validación)\n","test_steps = None\n","\n","# Definamos la tasa de aprendizaje\n","learning_rate = None\n","\n","# Número de clases\n","class_num = None\n","\n","# Estructura de la red neuronal convolucionales\n","filter_conv1 = None\n","size_filter1 = None\n","\n","filter_conv2 = None\n","size_filter2 = None\n","\n","#Usaremos un Max Pooling\n","size_pool = None\n","\n","\n","# 1. Antes de comenzar con el modelo, vamos a preprocesar las imágenes\n","train_data_generator = ImageDataGenerator(\n","    rescale = None,          # Normalizar los valores de los pixeles\n","    shear_range= None,           # Rango del ángulo que podemos inclinar nuestras imágenes\n","    zoom_range = None,            # Rango del zoom que podemos hacer a nuestras imágenes\n","    horizontal_flip = None       # Invierte imágenes\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","    rescale = None           # Normalizar los valores de los pixeles\n",")\n","\n","# Accede al directorio, preprocesa las imágenes y organiza en mini-batchs\n","train_images = train_data_generator.flow_from_directory(\n","    None,\n","    target_size = None,             # Tamaño de las imágenes\n","    batch_size = None,              # Tamaño del mini-batch\n","    class_mode = None'            # Modelo para clasificación\n",")\n","\n","# Accede al directorio, preprocesa las imágenes y organiza en mini-batchs\n","test_images = test_data_generator.flow_from_directory(\n","    None,\n","    target_size = None,\n","    batch_size = None,\n","    class_mode = None\n",")\n","\n","\n","# 2. Crear la ConvNet\n","cnn = Sequential()\n","\n","cnn.add(Convolution2D(None, None, padding=None, input_shape=(None, None,3), activation=None))\n","\n","cnn.add(MaxPooling2D(pool_size=None))\n","\n","cnn.add(Convolution2D(None, None, padding=None, activation=None))\n","\n","cnn.add(MaxPooling2D(pool_size=None))\n","\n","cnn.add(Flatten())\n","\n","cnn.add(Dense(None, activation=None))\n","\n","cnn.add(Dropout(None))\n","\n","cnn.add(Dense(None, activation=None))\n","\n","cnn.compile(loss=None, optimizer=optimizers.Adam(lr=None), metrics=[None])\n","\n","cnn.fit(None, steps_per_epoch=None, epochs=None, validation_data = None, validation_steps=None)\n","\n","# Definamos donde queremos guardar nuestro modelo y los pesos\n","dir='/content/gdrive/My Drive/Colab Notebooks/model/'\n","\n","if not os.path.exists(dir):\n","    os.mkdir(dir)\n","    \n","cnn.save('/content/gdrive/My Drive/Colab Notebooks/model/model.h5')\n","cnn.save_weights('/content/gdrive/My Drive/Colab Notebooks/model/weights.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUZUCen8o8iR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}